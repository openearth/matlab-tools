{
 "metadata": {
  "name": "",
  "signature": "sha256:80c0068a1e58fc2fae99934e636bb701620571506230433bc0817fd31020b0dc"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import datetime\n",
      "import re\n",
      "import zipfile\n",
      "import os\n",
      "\n",
      "import numpy as np\n",
      "import scipy.interpolate\n",
      "import pyproj\n",
      "import netCDF4\n",
      "import pandas\n",
      "\n",
      "PSMSLNAME=re.compile(r'(?P<id>\\d+)\\.rlrdata$')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "PSMSL data"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# open the zip file\n",
      "zf = zipfile.ZipFile('rlr_monthly.zip')\n",
      "# create dataframes for each time series\n",
      "dfs = []\n",
      "for info in zf.filelist:\n",
      "    # only loop over data\n",
      "    if not info.filename.endswith('rlrdata'):\n",
      "        continue\n",
      "    # open the file\n",
      "    f = zf.open(info.filename)\n",
      "    # load it as a csv file\n",
      "    df = pandas.read_csv(f, sep=';', header=None, index_col=None)\n",
      "    # set the columns (found in matlab parser)\n",
      "    df.columns = ['year.month', 'waterlevel', 'missing', 'dataflag']\n",
      "    id = int(PSMSLNAME.search(info.filename).group('id'))\n",
      "    df[\"id\"] = id\n",
      "    dfs.append(df)\n",
      "# group \n",
      "series_df = pandas.concat(dfs)\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# read the overview\n",
      "f = zf.open('rlr_monthly/filelist.txt')\n",
      "overview_df = pandas.DataFrame.from_csv(f, sep=';', header=None, index_col=None)\n",
      "overview_df.columns = ['id', 'latitude', 'longitude', 'name', 'coastline', 'stationcode', 'stationflag']         \n",
      "overview_df[\"name\"] = overview_df[\"name\"].apply(str.strip)\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": true,
     "input": [
      "dfs = []\n",
      "for stationfile in os.listdir('extra'):\n",
      "    if stationfile == 'stations.csv':\n",
      "        continue\n",
      "    df = pandas.read_csv(os.path.join('extra', stationfile))\n",
      "    dfs.append(df)\n",
      "series_df = pandas.concat(dfs + [series_df.copy()])\n",
      "\n",
      "df = pandas.read_csv(os.path.join('extra', 'stations.csv'))\n",
      "overview_df = overview_df.append(df)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# curry the time series\n",
      "# No missings in ints (http://pandas.pydata.org/pandas-docs/stable/gotchas.html)\n",
      "series_df[\"waterlevel\"] = series_df.waterlevel.astype('double')\n",
      "series_df[\"waterlevel\"][series_df[\"waterlevel\"] == -99999] = None\n",
      "# date time transformation\n",
      "series_df[\"year\"] = np.floor(series_df[\"year.month\"])\n",
      "overview_df = overview_df.set_index('id')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": true,
     "input": [
      "# avoid memory error?!\n",
      "series_df[\"month\"] = np.floor((np.array(series_df[\"year.month\"])- np.array(series_df[\"year\"]))*12 )+1\n",
      "# make datetimes\n",
      "f = lambda x: datetime.datetime(int(x[\"year\"]), int(x[\"month\"]),1)\n",
      "series_df[\"time\"] = pandas.to_datetime(series_df[[\"year\", \"month\"]].apply(f, axis=1))\n",
      "# lookup  station id\n",
      "\n",
      "data_grouped = series_df.groupby([\"id\"])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 6
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "GIA"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Read the GIA file\n",
      "ds = netCDF4.Dataset('./dsea250.1grid.ICE5Gv1.3_VM2_L90_2012.nc')\n",
      "lon = ds.variables['Lon'][:]\n",
      "lat = ds.variables['Lat'][:]\n",
      "dsea = ds.variables['Dsea_250'][:]\n",
      "print ds.variables['Dsea_250'].dimensions\n",
      "ds.close()\n",
      "# flip for increasing lat\n",
      "dsea = dsea[::-1,:] # flipud\n",
      "lon = np.mod(np.deg2rad(lon), np.pi*2)\n",
      "lat = np.deg2rad(lat[::-1]) + 0.5*np.pi # flip\n",
      "# interpolate on the earth\n",
      "F = scipy.interpolate.RectSphereBivariateSpline(u=lat, v=lon, r=dsea)\n",
      "overview_df[\"peltier\"] = F.ev(np.deg2rad(overview_df.latitude) + 0.5*np.pi, np.mod(np.deg2rad(overview_df.longitude), np.pi*2))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "(u'Lat', u'Lon')\n"
       ]
      }
     ],
     "prompt_number": 7
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Reanalysis"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Read wind reanalysis\n",
      "ds = netCDF4.Dataset('uwnd.10m.mon.mean.nc')\n",
      "lon = ds.variables['lon'][:]\n",
      "lat = ds.variables['lat'][:]\n",
      "u = ds.variables['uwnd'][:]\n",
      "time = netCDF4.num2date(ds.variables['time'][:], ds.variables['time'].units)\n",
      "print ds.variables['uwnd'].dimensions\n",
      "ds.close()\n",
      "lon = np.mod(np.deg2rad(lon), np.pi*2)\n",
      "lat = np.deg2rad(lat[::-1]) + 0.5*np.pi # flip\n",
      "u = u[:,::-1,:]\n",
      "ds = netCDF4.Dataset('vwnd.10m.mon.mean.nc')\n",
      "v = ds.variables['vwnd'][:]\n",
      "ds.close()\n",
      "v = v[:,::-1,:]\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "(u'time', u'lat', u'lon')\n"
       ]
      }
     ],
     "prompt_number": 8
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Interpolate on the earth, to each station\n",
      "dfs = []\n",
      "for i, t in enumerate(time):\n",
      "    F_i = scipy.interpolate.RectSphereBivariateSpline(u=lat, v=lon, r=u[i,:,:])\n",
      "    u_i = F_i.ev(np.deg2rad(overview_df.latitude) + 0.5*np.pi, np.mod(np.deg2rad(overview_df.longitude), np.pi*2))\n",
      "    F_i = scipy.interpolate.RectSphereBivariateSpline(u=lat, v=lon, r=v[i,:,:])    \n",
      "    v_i = F_i.ev(np.deg2rad(overview_df.latitude) + 0.5*np.pi, np.mod(np.deg2rad(overview_df.longitude), np.pi*2))\n",
      "    df = overview_df[[]].reset_index()\n",
      "    df[\"u_i\"] = u_i\n",
      "    df[\"v_i\"] = v_i\n",
      "    df[\"time\"] = t\n",
      "    dfs.append(df)\n",
      "df = pandas.concat(dfs)\n",
      "uv_grouped = df.groupby([\"id\"])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 9
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Inverse barometer correction\n",
      "=============================\n",
      "\n",
      "IB (mm) = -9.948 * ( d Rdry (mbars) - 1013.3 )"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Do an inverse barometer correction\n",
      "ds = netCDF4.Dataset('./slp.mnmean.real.nc')\n",
      "time = netCDF4.num2date(ds.variables['time'][:],ds.variables['time'].units)\n",
      "lon = ds.variables['lon'][:].astype('double')\n",
      "lat = ds.variables['lat'][:].astype('double')\n",
      "slp = ds.variables['slp'][:].astype('double')\n",
      "print ds.variables['slp'].dimensions\n",
      "ds.close()\n",
      "\n",
      "ds = netCDF4.Dataset(\"landmask.nc\")\n",
      "landmask = ds.variables[\"mask\"][:][::-1,:].astype(\"bool\") # no need to flip\n",
      "ds.close()\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "(u'time', u'lat', u'lon')\n"
       ]
      }
     ],
     "prompt_number": 10
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "slp_mask=np.tile(landmask[np.newaxis, :,:], (slp.shape[0], 1,1))\n",
      "slp_masked = np.ma.masked_array(slp, mask=slp_mask)\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 11
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "area_weight = np.ma.masked_array(\n",
      "            np.tile(np.cos(np.rad2deg(lat))[np.newaxis,:,np.newaxis], (slp_masked.shape[0], 1, slp_masked.shape[2])),\n",
      "            slp_mask        \n",
      "                    )\n",
      "glob_p = (slp_masked*area_weight).sum(1).sum(1)\n",
      "glob_p /= area_weight.sum(1).sum(1)\n",
      "\n",
      "IB = -(slp_masked-np.tile(glob_p[:,np.newaxis, np.newaxis], (1,slp_masked.shape[1],slp_masked.shape[2])))*0.9948"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 12
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Lookup closest IB for each station (interpolation breaks because of the landmasks)\n",
      "wgs84 = pyproj.Geod(ellps='WGS84')\n",
      "Lon, Lat = np.meshgrid(lon, lat)\n",
      "\n",
      "lon1, lat1 = Lon.ravel(), Lat.ravel()\n",
      "\n",
      "\n",
      "dfs = []\n",
      "for id, row in overview_df.iterrows():\n",
      "    lon2, lat2 = np.ones_like(Lon.ravel())*row['longitude'], np.ones_like(Lat.ravel())*row['latitude']\n",
      "    az1, az2, dist = wgs84.inv(lon1, lat1, lon2, lat2)\n",
      "    dist_masked = np.ma.masked_array(dist.reshape(Lon.shape), mask=landmask[:,:])\n",
      "    idx = np.unravel_index(dist_masked.argmin(), dist_masked.shape)\n",
      "    ib = IB[:, idx[0], idx[1]]\n",
      "    df = pandas.DataFrame(data=dict(time=time, ib=ib))\n",
      "    df['id'] = id\n",
      "    dfs.append(df)\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 13
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "ib_dfs = pandas.concat(dfs)\n",
      "ib_grouped = ib_dfs.groupby(['id'])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Merge data "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "merges = []\n",
      "for station, row in overview_df.iterrows():\n",
      "    uv = uv_grouped.get_group(station)\n",
      "    ib = ib_grouped.get_group(station)\n",
      "    data = data_grouped.get_group(station)\n",
      "    merged = pandas.merge(data, ib, how=\"left\", on=(\"time\",\"id\"))\n",
      "    merged = pandas.merge(merged, uv, how=\"left\", on=(\"time\", \"id\"))\n",
      "    merges.append(merged)\n",
      "dataset = pandas.concat(merges)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "dataset[\"u2\"] = dataset[\"u_i\"]**2\n",
      "dataset[\"v2\"] = dataset[\"v_i\"]**2\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Aggregate"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "output = dataset[['id', 'year', 'waterlevel', 'ib', 'u_i', 'v_i', \"u2\", \"v2\"]]\n",
      "year_df = dataset[[\"id\",\"year\", \"waterlevel\", \"ib\", \"u_i\",\"v_i\", \"u2\", \"v2\"]].groupby(['id', 'year']).mean()\n",
      "year_df = year_df.reset_index()\n",
      "year_df.rename(columns={'year': 'year.month'}, inplace=True)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 44
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "output.to_csv(\"records.csv\", index=False)\n",
      "year_df.to_csv(\"records_annual.csv\", index=False)\n",
      "overview_df.to_csv(\"overview.csv\", index=True, index_label=\"id\")\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 45
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}